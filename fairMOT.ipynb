{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Load configs from yml files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Fix size testing.\n",
      "heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n",
      "{'K': 500,\n",
      " 'arch': 'dla_34',\n",
      " 'batch_size': 2,\n",
      " 'cat_spec_wh': False,\n",
      " 'conf_thres': 0.3,\n",
      " 'config_path': './default_config.yaml',\n",
      " 'data_cfg': './data/data.json',\n",
      " 'data_dir': '/home/dataset',\n",
      " 'data_url': '',\n",
      " 'dataset': 'jde',\n",
      " 'dense_wh': False,\n",
      " 'det_thres': 0.3,\n",
      " 'device': 'GPU',\n",
      " 'down_ratio': 4,\n",
      " 'fix_res': True,\n",
      " 'head_conv': 256,\n",
      " 'heads': {'hm': 1, 'id': 128, 'reg': 2, 'wh': 4},\n",
      " 'hm_weight': 1,\n",
      " 'id': 0,\n",
      " 'id_loss': 'ce',\n",
      " 'id_weight': 1,\n",
      " 'img_size': (1088, 608),\n",
      " 'input-video': '/videos/MOT16-03.mp4',\n",
      " 'input_h': 608,\n",
      " 'input_res': 1088,\n",
      " 'input_video': '/videos/MOT16-03.mp4',\n",
      " 'input_w': 1088,\n",
      " 'is_modelarts': False,\n",
      " 'keep_res': False,\n",
      " 'load_model': '',\n",
      " 'load_pre_model': './crowdhuman_dla34_ms.ckpt',\n",
      " 'lr': 0.0001,\n",
      " 'ltrb': True,\n",
      " 'mean': [0.408, 0.447, 0.47],\n",
      " 'min-box-area': 100,\n",
      " 'min_box_area': 100,\n",
      " 'mse_loss': False,\n",
      " 'nID': 14455,\n",
      " 'nms_thres': 0.4,\n",
      " 'norm_wh': False,\n",
      " 'not_prefetch_test': False,\n",
      " 'not_reg_offset': False,\n",
      " 'num_classes': 1,\n",
      " 'num_epochs': 30,\n",
      " 'num_stacks': 1,\n",
      " 'off_weight': 1,\n",
      " 'output-format': 'video',\n",
      " 'output-root': './exports',\n",
      " 'output_format': 'video',\n",
      " 'output_h': 152,\n",
      " 'output_res': 272,\n",
      " 'output_root': './exports',\n",
      " 'output_w': 272,\n",
      " 'pad': 31,\n",
      " 'reg_loss': 'l1',\n",
      " 'reg_offset': True,\n",
      " 'reid_dim': 128,\n",
      " 'run_distribute': False,\n",
      " 'std': [0.289, 0.274, 0.278],\n",
      " 'track_buffer': 30,\n",
      " 'train_url': '',\n",
      " 'wh_weight': 0.1,\n",
      " 'workers': 6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import ast\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    Configuration namespace. Convert dictionary to members.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg_dict):\n",
    "        for k, v in cfg_dict.items():\n",
    "            if isinstance(v, (list, tuple)):\n",
    "                setattr(self, k, [Config(x) if isinstance(x, dict) else x for x in v])\n",
    "            else:\n",
    "                setattr(self, k, Config(v) if isinstance(v, dict) else v)\n",
    "\n",
    "    def __str__(self):\n",
    "        return pformat(self.__dict__)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "def parse_cli_to_yaml(parser, cfg, helper=None, choices=None, cfg_path=\"default_config.yaml\"):\n",
    "    \"\"\"\n",
    "    Parse command line arguments to the configuration according to the default yaml.\n",
    "\n",
    "    Args:\n",
    "        parser: Parent parser.\n",
    "        cfg: Base configuration.\n",
    "        helper: Helper description.\n",
    "        cfg_path: Path to the default yaml config.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"[REPLACE THIS at config.py]\",\n",
    "                                     parents=[parser])\n",
    "    helper = {} if helper is None else helper\n",
    "    choices = {} if choices is None else choices\n",
    "    for item in cfg:\n",
    "        if not isinstance(cfg[item], list) and not isinstance(cfg[item], dict):\n",
    "            help_description = helper[item] if item in helper else \"Please reference to {}\".format(cfg_path)\n",
    "            choice = choices[item] if item in choices else None\n",
    "            if isinstance(cfg[item], bool):\n",
    "                parser.add_argument(\"--\" + item, type=ast.literal_eval, default=cfg[item], choices=choice,\n",
    "                                    help=help_description)\n",
    "            else:\n",
    "                parser.add_argument(\"--\" + item, type=type(cfg[item]), default=cfg[item], choices=choice,\n",
    "                                    help=help_description)\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "\n",
    "def parse_yaml(yaml_path):\n",
    "    \"\"\"\n",
    "    Parse the yaml config file.\n",
    "\n",
    "    Args:\n",
    "        yaml_path: Path to the yaml config.\n",
    "    \"\"\"\n",
    "    with open(yaml_path, 'r') as fin:\n",
    "        try:\n",
    "            cfgs = yaml.load_all(fin.read(), Loader=yaml.FullLoader)\n",
    "            cfgs = [x for x in cfgs]\n",
    "            if len(cfgs) == 1:\n",
    "                cfg_helper = {}\n",
    "                cfg = cfgs[0]\n",
    "                cfg_choices = {}\n",
    "            elif len(cfgs) == 2:\n",
    "                cfg, cfg_helper = cfgs\n",
    "                cfg_choices = {}\n",
    "            elif len(cfgs) == 3:\n",
    "                cfg, cfg_helper, cfg_choices = cfgs\n",
    "            else:\n",
    "                raise ValueError(\"At most 3 docs (config, description for help, choices) are supported in config yaml\")\n",
    "            print(cfg_helper)\n",
    "        except:\n",
    "            raise ValueError(\"Failed to parse yaml\")\n",
    "    return cfg, cfg_helper, cfg_choices\n",
    "\n",
    "\n",
    "def merge(args, cfg):\n",
    "    \"\"\"\n",
    "    Merge the base config from yaml file and command line arguments.\n",
    "\n",
    "    Args:\n",
    "        args: Command line arguments.\n",
    "        cfg: Base configuration.\n",
    "    \"\"\"\n",
    "    args_var = vars(args)\n",
    "    for item in args_var:\n",
    "        cfg[item] = args_var[item]\n",
    "    return cfg\n",
    "\n",
    "\n",
    "class Opts:\n",
    "    \"\"\"\n",
    "    parameter configuration\n",
    "    \"\"\"\n",
    "    def __init__(self, args=''):\n",
    "        self.config = self.init(args)\n",
    "\n",
    "    def parse(self, args=''):\n",
    "        \"\"\"parameter parse\"\"\"\n",
    "        parser = argparse.ArgumentParser(description=\"default name\", add_help=False)\n",
    "        parser.add_argument(\"--config_path\", type=str, default=\"./default_config.yaml\",\n",
    "                            help=\"Config file path\")\n",
    "        path_args, _ = parser.parse_known_args()\n",
    "        default, helper, choices = parse_yaml(path_args.config_path)\n",
    "        args = parse_cli_to_yaml(parser=parser, cfg=default, helper=helper, choices=choices,\n",
    "                                 cfg_path=path_args.config_path)\n",
    "        default = Config(merge(args, default))\n",
    "\n",
    "        default.fix_res = not default.keep_res\n",
    "        print('Fix size testing.' if default.fix_res else 'Keep resolution testing.')\n",
    "        default.reg_offset = not default.not_reg_offset\n",
    "\n",
    "        if default.head_conv == -1:  # init default head_conv\n",
    "            default.head_conv = 256 if 'dla' in default.arch else 256\n",
    "        default.pad = 31\n",
    "        default.num_stacks = 1\n",
    "\n",
    "        return default\n",
    "\n",
    "    def update_dataset_info_and_set_heads(self, opt, dataset):\n",
    "        \"\"\"update dataset info and set heads\"\"\"\n",
    "        input_h, input_w = dataset.default_resolution\n",
    "        opt.mean, opt.std = dataset.mean, dataset.std\n",
    "        opt.num_classes = dataset.num_classes\n",
    "\n",
    "        # input_h(w): opt.input_h overrides opt.input_res overrides dataset default\n",
    "        input_h = opt.input_res if opt.input_res > 0 else input_h\n",
    "        input_w = opt.input_res if opt.input_res > 0 else input_w\n",
    "        opt.input_h = opt.input_h if opt.input_h > 0 else input_h\n",
    "        opt.input_w = opt.input_w if opt.input_w > 0 else input_w\n",
    "        opt.output_h = opt.input_h // opt.down_ratio\n",
    "        opt.output_w = opt.input_w // opt.down_ratio\n",
    "        opt.input_res = max(opt.input_h, opt.input_w)\n",
    "        opt.output_res = max(opt.output_h, opt.output_w)\n",
    "\n",
    "        opt.heads = {'hm': opt.num_classes,\n",
    "                     'wh': 2 if not opt.ltrb else 4,\n",
    "                     'id': opt.reid_dim}\n",
    "        if opt.reg_offset:\n",
    "            opt.heads.update({'reg': 2})\n",
    "        opt.nID = dataset.nID\n",
    "        opt.img_size = (1088, 608)\n",
    "        print('heads', opt.heads)\n",
    "        return opt\n",
    "\n",
    "    def init(self, args=''):\n",
    "        \"\"\"opt init\"\"\"\n",
    "        default_dataset_info = {\n",
    "            'mot': {'default_resolution': [608, 1088], 'num_classes': 1,\n",
    "                    'mean': [0.408, 0.447, 0.470], 'std': [0.289, 0.274, 0.278],\n",
    "                    'dataset': 'jde', 'nID': 14455},\n",
    "        }\n",
    "\n",
    "        class Struct:\n",
    "            \"\"\"opt struct\"\"\"\n",
    "            def __init__(self, entries):\n",
    "                for k, v in entries.items():\n",
    "                    self.__setattr__(k, v)\n",
    "\n",
    "        opt = self.parse(args)\n",
    "        dataset = Struct(default_dataset_info['mot'])\n",
    "        opt.dataset = dataset.dataset\n",
    "        opt = self.update_dataset_info_and_set_heads(opt, dataset)\n",
    "        return opt\n",
    "\n",
    "    def get_config(self):\n",
    "        return self.config\n",
    "\n",
    "\n",
    "opt = Opts().get_config()\n",
    "print(opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nID 11932\n",
      "nds [11206]\n",
      "cds [0]\n",
      "================================================================================\n",
      "dataset summary\n",
      "OrderedDict([('cuhksysu', 11931.0)])\n",
      "total # identities: 11932\n",
      "start index\n",
      "OrderedDict([('cuhksysu', 0)])\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import mindspore.dataset as ds\n",
    "import collections\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def gaussian2D(shape, sigma=1):\n",
    "    \"\"\"gaussian2D\"\"\"\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m + 1, -n:n + 1]\n",
    "\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    return h\n",
    "\n",
    "\n",
    "def draw_umich_gaussian(heatmap, center, radius, k=1):\n",
    "    \"\"\"draw umich gaussian\"\"\"\n",
    "    diameter = 2 * radius + 1\n",
    "    gaussian = gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "\n",
    "    x, y = int(center[0]), int(center[1])\n",
    "\n",
    "    height, width = heatmap.shape[0:2]\n",
    "\n",
    "    left, right = min(x, radius), min(width - x, radius + 1)\n",
    "    top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "    masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "    masked_gaussian = gaussian[radius - top:radius + bottom, radius - left:radius + right]\n",
    "    if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0:\n",
    "        np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "\n",
    "def draw_msra_gaussian(heatmap, center, sigma):\n",
    "    \"\"\"draw msra gaussian\"\"\"\n",
    "    tmp_size = sigma * 3\n",
    "    mu_x = int(center[0] + 0.5)\n",
    "    mu_y = int(center[1] + 0.5)\n",
    "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
    "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
    "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
    "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
    "        return heatmap\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = np.arange(0, size, 1, np.float32)\n",
    "    y = x[:, np.newaxis]\n",
    "    x0 = y0 = size // 2\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
    "    img_x = max(0, ul[0]), min(br[0], h)\n",
    "    img_y = max(0, ul[1]), min(br[1], w)\n",
    "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
    "        heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
    "        g[g_y[0]:g_y[1], g_x[0]:g_x[1]])\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def gaussian_radius(det_size, min_overlap=0.7):\n",
    "    \"\"\"gaussian radius\"\"\"\n",
    "    height, width = det_size\n",
    "\n",
    "    a1 = 1\n",
    "    b1 = (height + width)\n",
    "    c1 = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "    r1 = (b1 + sq1) / 2\n",
    "\n",
    "    a2 = 4\n",
    "    b2 = 2 * (height + width)\n",
    "    c2 = (1 - min_overlap) * width * height\n",
    "    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "    r2 = (b2 + sq2) / 2\n",
    "\n",
    "    a3 = 4 * min_overlap\n",
    "    b3 = -2 * min_overlap * (height + width)\n",
    "    c3 = (min_overlap - 1) * width * height\n",
    "    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "    r3 = (b3 + sq3) / 2\n",
    "    return min(r1, r2, r3)\n",
    "\n",
    "\n",
    "\n",
    "def letterbox(img, height=608, width=1088,\n",
    "              color=(127.5, 127.5, 127.5)):\n",
    "    \"\"\"resize a rectangular image to a padded rectangular\"\"\"\n",
    "    shape = img.shape[:2]  # shape = [height, width]\n",
    "    ratio = min(float(height) / shape[0], float(width) / shape[1])\n",
    "    new_shape = (round(shape[1] * ratio), round(shape[0] * ratio))  # new_shape = [width, height]\n",
    "    dw = (width - new_shape[0]) / 2  # width padding\n",
    "    dh = (height - new_shape[1]) / 2  # height padding\n",
    "    top, bottom = round(dh - 0.1), round(dh + 0.1)\n",
    "    left, right = round(dw - 0.1), round(dw + 0.1)\n",
    "    img = cv2.resize(img, new_shape, interpolation=cv2.INTER_AREA)  # resized, no border\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # padded rectangular\n",
    "    return img, ratio, dw, dh\n",
    "\n",
    "\n",
    "def xyxy2xywh(x):\n",
    "    # Convert bounding box format from [x1, y1, x2, y2] to [x, y, w, h]\n",
    "    y = np.zeros(x.shape)\n",
    "    y[:, 0] = (x[:, 0] + x[:, 2]) / 2\n",
    "    y[:, 1] = (x[:, 1] + x[:, 3]) / 2\n",
    "    y[:, 2] = x[:, 2] - x[:, 0]\n",
    "    y[:, 3] = x[:, 3] - x[:, 1]\n",
    "    return y\n",
    "\n",
    "def random_affine(img, targets=None, degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-2, 2),\n",
    "                  borderValue=(127.5, 127.5, 127.5)):\n",
    "    \"\"\"\n",
    "    https://medium.com/uruvideo/dataset-augmentation-with-random-homographies-a8f4b44830d4\n",
    "    \"\"\"\n",
    "\n",
    "    border = 0  # width of added border (optional)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "\n",
    "    # Rotation and Scale\n",
    "    R = np.eye(3)\n",
    "    a = random.random() * (degrees[1] - degrees[0]) + degrees[0]\n",
    "    # a += random.choice([-180, -90, 0, 90])  # 90deg rotations added to small rotations\n",
    "    s = random.random() * (scale[1] - scale[0]) + scale[0]\n",
    "    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(img.shape[1] / 2, img.shape[0] / 2), scale=s)\n",
    "\n",
    "    # Translation\n",
    "    T = np.eye(3)\n",
    "    T[0, 2] = (random.random() * 2 - 1) * translate[0] * img.shape[0] + border  # x translation (pixels)\n",
    "    T[1, 2] = (random.random() * 2 - 1) * translate[1] * img.shape[1] + border  # y translation (pixels)\n",
    "\n",
    "    # Shear\n",
    "    S = np.eye(3)\n",
    "    S[0, 1] = math.tan((random.random() * (shear[1] - shear[0]) + shear[0]) * math.pi / 180)  # x shear (deg)\n",
    "    S[1, 0] = math.tan((random.random() * (shear[1] - shear[0]) + shear[0]) * math.pi / 180)  # y shear (deg)\n",
    "\n",
    "    M = np.matmul(S, np.matmul(T, R))  # Combined rotation matrix. ORDER IS IMPORTANT HERE!!\n",
    "    imw = cv2.warpPerspective(img, M, dsize=(width, height), flags=cv2.INTER_LINEAR,\n",
    "                              borderValue=borderValue)  # BGR order borderValue\n",
    "\n",
    "    # Return warped points also\n",
    "    if targets is not None:\n",
    "        if np.shape(targets)[0] > 0:\n",
    "            n = targets.shape[0]\n",
    "            points = targets[:, 2:6].copy()\n",
    "            area0 = (points[:, 2] - points[:, 0]) * (points[:, 3] - points[:, 1])\n",
    "\n",
    "            # warp points\n",
    "            xy = np.ones((n * 4, 3))\n",
    "            xy[:, :2] = points[:, [0, 1, 2, 3, 0, 3, 2, 1]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1\n",
    "            xy = np.matmul(xy, M.T)[:, :2].reshape(n, 8)\n",
    "            # create new boxes\n",
    "            x = xy[:, [0, 2, 4, 6]]\n",
    "            y = xy[:, [1, 3, 5, 7]]\n",
    "            xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n",
    "\n",
    "            # apply angle-based reduction\n",
    "            radians = a * math.pi / 180\n",
    "            reduction = max(abs(math.sin(radians)), abs(math.cos(radians))) ** 0.5\n",
    "            x = (xy[:, 2] + xy[:, 0]) / 2\n",
    "            y = (xy[:, 3] + xy[:, 1]) / 2\n",
    "            w = (xy[:, 2] - xy[:, 0]) * reduction\n",
    "            h = (xy[:, 3] - xy[:, 1]) * reduction\n",
    "            xy = np.concatenate((x - w / 2, y - h / 2, x + w / 2, y + h / 2)).reshape(4, n).T\n",
    "\n",
    "            # reject warped points outside of image\n",
    "            # np.clip(xy[:, 0], 0, width, out=xy[:, 0])\n",
    "            # np.clip(xy[:, 2], 0, width, out=xy[:, 2])\n",
    "            # np.clip(xy[:, 1], 0, height, out=xy[:, 1])\n",
    "            # np.clip(xy[:, 3], 0, height, out=xy[:, 3])\n",
    "            w = xy[:, 2] - xy[:, 0]\n",
    "            h = xy[:, 3] - xy[:, 1]\n",
    "            area = w * h\n",
    "            ar = np.maximum(w / (h + 1e-16), h / (w + 1e-16))\n",
    "            i = (w > 4) & (h > 4) & (area / (area0 + 1e-16) > 0.1) & (ar < 10)\n",
    "\n",
    "            targets = targets[i]\n",
    "            targets[:, 2:6] = xy[i]\n",
    "\n",
    "        return imw, targets, M\n",
    "    return imw\n",
    "\n",
    "\n",
    "class JointDataset:\n",
    "    \"\"\" for training\"\"\"\n",
    "\n",
    "    default_resolution = [1088, 608]\n",
    "    mean = None\n",
    "    std = None\n",
    "    num_classes = 1\n",
    "\n",
    "    def __init__(self, opt, root, paths, img_size=(1088, 608), augment=False):\n",
    "        self.opt = opt\n",
    "        self.img_files = collections.OrderedDict()\n",
    "        self.label_files = collections.OrderedDict()\n",
    "        self.tid_num = collections.OrderedDict()\n",
    "        self.tid_start_index = collections.OrderedDict()\n",
    "        self.num_classes = 1\n",
    "        for ds, path in paths.items():\n",
    "            path = osp.join(root, path)\n",
    "            with open(path, 'r') as file:\n",
    "                self.img_files[ds] = file.readlines()\n",
    "                self.img_files[ds] = [osp.join(root, x.strip()) for x in self.img_files[ds]]\n",
    "                self.img_files[ds] = list(filter(lambda x: len(x) > 0, self.img_files[ds]))\n",
    "            self.label_files[ds] = [\n",
    "                x.replace('images', 'labels_with_ids').replace('.png', '.txt').replace('.jpg', '.txt')\n",
    "                for x in self.img_files[ds]]\n",
    "        for ds, label_paths in self.label_files.items():\n",
    "            max_index = -1\n",
    "            for lp in label_paths:\n",
    "                lb = np.loadtxt(lp)\n",
    "                if np.shape(lb)[0] < 1:\n",
    "                    continue\n",
    "                if len(lb.shape) < 2:\n",
    "                    img_max = lb[1]\n",
    "                else:\n",
    "                    img_max = np.max(lb[:, 1])\n",
    "                if img_max > max_index:\n",
    "                    max_index = img_max\n",
    "            self.tid_num[ds] = max_index + 1\n",
    "        last_index = 0\n",
    "        for k, v in self.tid_num.items():\n",
    "            self.tid_start_index[k] = last_index\n",
    "            last_index += v\n",
    "        self.nID = int(last_index + 1)  # 多个数据集中总的identity数目\n",
    "        print('nID', self.nID)\n",
    "        self.nds = [len(x) for x in self.img_files.values()]  # 图片数量\n",
    "        print('nds', self.nds)\n",
    "        self.cds = [sum(self.nds[:i]) for i in range(len(self.nds))]\n",
    "        print('cds', self.cds)\n",
    "        self.nF = sum(self.nds)\n",
    "        self.width = img_size[0]\n",
    "        self.height = img_size[1]\n",
    "        self.max_objs = opt.K\n",
    "        self.augment = augment\n",
    "\n",
    "        print('=' * 80)\n",
    "        print('dataset summary')\n",
    "        print(self.tid_num)\n",
    "        print('total # identities:', self.nID)\n",
    "        print('start index')\n",
    "        print(self.tid_start_index)\n",
    "        print('=' * 80)\n",
    "\n",
    "    def __getitem__(self, files_index):\n",
    "\n",
    "        for i, c in enumerate(self.cds):\n",
    "            if files_index >= c:\n",
    "                ds = list(self.label_files.keys())[i]\n",
    "                start_index = c\n",
    "\n",
    "        img_path = self.img_files[ds][files_index - start_index]\n",
    "        label_path = self.label_files[ds][files_index - start_index]\n",
    "        imgs, labels, img_path = self.get_data(img_path, label_path)\n",
    "        for i, _ in enumerate(labels):\n",
    "            if labels[i, 1] > -1:\n",
    "                labels[i, 1] += self.tid_start_index[ds]\n",
    "\n",
    "        output_h = imgs.shape[1] // self.opt.down_ratio\n",
    "        output_w = imgs.shape[2] // self.opt.down_ratio\n",
    "        num_classes = self.num_classes\n",
    "        num_objs = labels.shape[0]\n",
    "        hm = np.zeros((num_classes, output_h, output_w), dtype=np.float32)\n",
    "        if self.opt.ltrb:\n",
    "            wh = np.zeros((self.max_objs, 4), dtype=np.float32)\n",
    "        else:\n",
    "            wh = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "        reg = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "        ind = np.zeros((self.max_objs,), dtype=np.int32)\n",
    "        reg_mask = np.zeros((self.max_objs,), dtype=np.int32)\n",
    "        ids = np.zeros((self.max_objs,), dtype=np.int32)\n",
    "        bbox_xys = np.zeros((self.max_objs, 4), dtype=np.float32)\n",
    "\n",
    "        draw_gaussian = draw_msra_gaussian if self.opt.mse_loss else draw_umich_gaussian\n",
    "        for k in range(min(num_objs, self.max_objs)):\n",
    "            label = labels[k]\n",
    "            bbox = label[2:]\n",
    "            cls_id = int(label[0])\n",
    "            bbox[[0, 2]] = bbox[[0, 2]] * output_w\n",
    "            bbox[[1, 3]] = bbox[[1, 3]] * output_h\n",
    "            bbox_amodal = copy.deepcopy(bbox)\n",
    "            bbox_amodal[0] = bbox_amodal[0] - bbox_amodal[2] / 2.\n",
    "            bbox_amodal[1] = bbox_amodal[1] - bbox_amodal[3] / 2.\n",
    "            bbox_amodal[2] = bbox_amodal[0] + bbox_amodal[2]\n",
    "            bbox_amodal[3] = bbox_amodal[1] + bbox_amodal[3]\n",
    "            bbox[0] = np.clip(bbox[0], 0, output_w - 1)\n",
    "            bbox[1] = np.clip(bbox[1], 0, output_h - 1)\n",
    "            h = bbox[3]\n",
    "            w = bbox[2]\n",
    "\n",
    "            bbox_xy = copy.deepcopy(bbox)\n",
    "            bbox_xy[0] = bbox_xy[0] - bbox_xy[2] / 2\n",
    "            bbox_xy[1] = bbox_xy[1] - bbox_xy[3] / 2\n",
    "            bbox_xy[2] = bbox_xy[0] + bbox_xy[2]\n",
    "            bbox_xy[3] = bbox_xy[1] + bbox_xy[3]\n",
    "\n",
    "            if h > 0 and w > 0:\n",
    "                radius = gaussian_radius((math.ceil(h), math.ceil(w)))\n",
    "                radius = max(0, int(radius))\n",
    "                radius = 6 if self.opt.mse_loss else radius\n",
    "                # radius = max(1, int(radius)) if self.opt.mse_loss else radius\n",
    "                ct = np.array(\n",
    "                    [bbox[0], bbox[1]], dtype=np.float32)\n",
    "                ct_int = ct.astype(np.int32)\n",
    "                draw_gaussian(hm[cls_id], ct_int, radius)\n",
    "                if self.opt.ltrb:\n",
    "                    wh[k] = ct[0] - bbox_amodal[0], ct[1] - bbox_amodal[1], \\\n",
    "                            bbox_amodal[2] - ct[0], bbox_amodal[3] - ct[1]\n",
    "                else:\n",
    "                    wh[k] = 1. * w, 1. * h\n",
    "                ind[k] = ct_int[1] * output_w + ct_int[0]\n",
    "                reg[k] = ct - ct_int\n",
    "                reg_mask[k] = 1\n",
    "                ids[k] = label[1]\n",
    "                bbox_xys[k] = bbox_xy\n",
    "        # ret = {'input': imgs, 'hm': hm, 'reg_mask': reg_mask, 'ind': ind, 'wh': wh, 'reg': reg, 'ids': ids,\n",
    "        # 'bbox': bbox_xys}\n",
    "        return imgs, hm, reg_mask, ind, wh, reg, ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nF\n",
    "\n",
    "    def get_data(self, img_path, label_path):\n",
    "        \"\"\"get data\"\"\"\n",
    "        height = self.height\n",
    "        width = self.width\n",
    "        img = cv2.imread(img_path)  # BGR\n",
    "        if img is None:\n",
    "            raise ValueError('File corrupt {}'.format(img_path))\n",
    "        augment_hsv = True\n",
    "        if self.augment and augment_hsv:\n",
    "            # SV augmentation by 50%\n",
    "            fraction = 0.50\n",
    "            img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            S = img_hsv[:, :, 1].astype(np.float32)\n",
    "            V = img_hsv[:, :, 2].astype(np.float32)\n",
    "\n",
    "            a = (random.random() * 2 - 1) * fraction + 1\n",
    "            S *= a\n",
    "            if a > 1:\n",
    "                np.clip(S, a_min=0, a_max=255, out=S)\n",
    "\n",
    "            a = (random.random() * 2 - 1) * fraction + 1\n",
    "            V *= a\n",
    "            if a > 1:\n",
    "                np.clip(V, a_min=0, a_max=255, out=V)\n",
    "\n",
    "            img_hsv[:, :, 1] = S.astype(np.uint8)\n",
    "            img_hsv[:, :, 2] = V.astype(np.uint8)\n",
    "            cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)\n",
    "        h, w, _ = img.shape\n",
    "        img, ratio, padw, padh = letterbox(img, height=height, width=width)\n",
    "        # Load labels\n",
    "        if os.path.isfile(label_path):\n",
    "            labels0 = np.loadtxt(label_path, dtype=np.float32).reshape(-1, 6)\n",
    "\n",
    "            # Normalized xywh to pixel xyxy format\n",
    "            labels = labels0.copy()\n",
    "            labels[:, 2] = ratio * w * (labels0[:, 2] - labels0[:, 4] / 2) + padw\n",
    "            labels[:, 3] = ratio * h * (labels0[:, 3] - labels0[:, 5] / 2) + padh\n",
    "            labels[:, 4] = ratio * w * (labels0[:, 2] + labels0[:, 4] / 2) + padw\n",
    "            labels[:, 5] = ratio * h * (labels0[:, 3] + labels0[:, 5] / 2) + padh\n",
    "        else:\n",
    "            labels = np.array([])\n",
    "\n",
    "        # Augment image and labels\n",
    "        if self.augment:\n",
    "            img, labels, _ = random_affine(img, labels, degrees=(-5, 5), translate=(0.10, 0.10), scale=(0.50, 1.20))\n",
    "\n",
    "        plotFlag = False\n",
    "        if plotFlag:\n",
    "            import matplotlib\n",
    "            matplotlib.use('Agg')\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure(figsize=(50, 50))\n",
    "            plt.imshow(img[:, :, ::-1])\n",
    "            plt.plot(labels[:, [1, 3, 3, 1, 1]].T, labels[:, [2, 2, 4, 4, 2]].T, '.-')\n",
    "            plt.axis('off')\n",
    "            plt.savefig('test.jpg')\n",
    "            time.sleep(10)\n",
    "\n",
    "        nL = len(labels)\n",
    "        if nL > 0:\n",
    "            # convert xyxy to xywh\n",
    "            labels[:, 2:6] = xyxy2xywh(labels[:, 2:6].copy())  # / height\n",
    "            labels[:, 2] /= width\n",
    "            labels[:, 3] /= height\n",
    "            labels[:, 4] /= width\n",
    "            labels[:, 5] /= height\n",
    "        if self.augment:\n",
    "            # random left-right flip\n",
    "            lr_flip = True\n",
    "            if lr_flip & (random.random() > 0.5):\n",
    "                img = np.fliplr(img)\n",
    "                if nL > 0:\n",
    "                    labels[:, 2] = 1 - labels[:, 2]\n",
    "\n",
    "        img = np.ascontiguousarray(img[:, :, ::-1])  # BGR to RGB\n",
    "        img = np.array(img, dtype=np.float32) / 255\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        return img, labels, img_path\n",
    "\n",
    "\n",
    "dataset_root = \"/home/ubuntu/code/models-master/research/cv/fairmot/data\"\n",
    "train_set_paths = {\n",
    "        \"cuhksysu\":\"cuhksysu.train\"\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = JointDataset(opt, dataset_root, train_set_paths, (1088, 608), augment=True)\n",
    "\n",
    "\n",
    "Ms_dataset = ds.GeneratorDataset(dataset, ['input', 'hm', 'reg_mask', 'ind', 'wh', 'reg', 'ids'],\n",
    "                                         shuffle=True, num_parallel_workers=4,\n",
    "                                         max_rowsize=8,\n",
    "                                        )\n",
    "\n",
    "Ms_dataset = Ms_dataset.batch(batch_size=4, drop_remainder=True)\n",
    "batch_dataset_size = Ms_dataset.get_dataset_size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Copyright 2020 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "deep layer aggregation backbone\n",
    "\"\"\"\n",
    "\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.initializer import Constant\n",
    "\n",
    "BN_MOMENTUM = 0.1\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    Basic residual block for dla.\n",
    "\n",
    "    Args:\n",
    "        cin(int): Input channel.\n",
    "        cout(int): Output channel.\n",
    "        stride(int): Covolution stride. Default: 1.\n",
    "        dilation(int): The dilation rate to be used for dilated convolution. Default: 1.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, the feature after covolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cin, cout, stride=1, dilation=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv_bn_act = nn.Conv2dBnAct(cin, cout, kernel_size=3, stride=stride, pad_mode='pad',\n",
    "                                          padding=dilation, has_bias=False, dilation=dilation,\n",
    "                                          has_bn=True, momentum=BN_MOMENTUM,\n",
    "                                          activation='relu', after_fake=False)\n",
    "        self.conv_bn = nn.Conv2dBnAct(cout, cout, kernel_size=3, stride=1, pad_mode='same',\n",
    "                                      has_bias=False, dilation=dilation, has_bn=True,\n",
    "                                      momentum=BN_MOMENTUM, activation=None)\n",
    "        self.relu = ops.ReLU()\n",
    "\n",
    "    def construct(self, x, residual=None):\n",
    "        \"\"\"\n",
    "        Basic residual block for dla.\n",
    "        \"\"\"\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "\n",
    "        out = self.conv_bn_act(x)\n",
    "        out = self.conv_bn(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Root(nn.Cell):\n",
    "    \"\"\"\n",
    "    Get HDA node which play as the root of tree in each stage\n",
    "\n",
    "    Args:\n",
    "        cin(int): Input channel.\n",
    "        cout(int):Output channel.\n",
    "        kernel_size(int): Covolution kernel size.\n",
    "        residual(bool): Add residual or not.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, HDA node after aggregation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, residual):\n",
    "        super(Root, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, 1, stride=1, has_bias=False,\n",
    "                              pad_mode='pad', padding=(kernel_size - 1) // 2)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, momentum=BN_MOMENTUM)\n",
    "        self.relu = ops.ReLU()\n",
    "        self.residual = residual\n",
    "        self.cat = ops.Concat(axis=1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"\n",
    "        Get HDA node which play as the root of tree in each stage\n",
    "        \"\"\"\n",
    "        children = x\n",
    "        x = self.conv(self.cat(x))\n",
    "        x = self.bn(x)\n",
    "        if self.residual:\n",
    "            x += children[0]\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Tree(nn.Cell):\n",
    "    \"\"\"\n",
    "    Construct the deep aggregation network through recurrent. Each stage can be seen as a tree with multiple children.\n",
    "\n",
    "    Args:\n",
    "        levels(list int): Tree height of each stage.\n",
    "        block(Cell): Basic block of the tree.\n",
    "        in_channels(list int): Input channel of each stage.\n",
    "        out_channels(list int): Output channel of each stage.\n",
    "        stride(int): Covolution stride. Default: 1.\n",
    "        level_root(bool): Whether is the root of tree or not. Default: False.\n",
    "        root_dim(int): Input channel of the root node. Default: 0.\n",
    "        root_kernel_size(int): Covolution kernel size at the root. Default: 1.\n",
    "        dilation(int): The dilation rate to be used for dilated convolution. Default: 1.\n",
    "        root_residual(bool): Add residual or not. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, the root ida node.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, levels, block, in_channels, out_channels, stride=1, level_root=False,\n",
    "                 root_dim=0, root_kernel_size=1, dilation=1, root_residual=False):\n",
    "        super(Tree, self).__init__()\n",
    "        self.levels = levels\n",
    "        if root_dim == 0:\n",
    "            root_dim = 2 * out_channels\n",
    "        if level_root:\n",
    "            root_dim += in_channels\n",
    "        if self.levels == 1:\n",
    "            self.tree1 = block(in_channels, out_channels, stride, dilation=dilation)\n",
    "            self.tree2 = block(out_channels, out_channels, 1, dilation=dilation)\n",
    "        else:\n",
    "            self.tree1 = Tree(levels - 1, block, in_channels, out_channels, stride, root_dim=0,\n",
    "                              root_kernel_size=root_kernel_size, dilation=dilation, root_residual=root_residual)\n",
    "            self.tree2 = Tree(levels - 1, block, out_channels, out_channels, root_dim=root_dim + out_channels,\n",
    "                              root_kernel_size=root_kernel_size, dilation=dilation, root_residual=root_residual)\n",
    "        if self.levels == 1:\n",
    "            self.root = Root(root_dim, out_channels, root_kernel_size, root_residual)\n",
    "        self.level_root = level_root\n",
    "        self.root_dim = root_dim\n",
    "        self.downsample = None\n",
    "        self.project = None\n",
    "        if stride > 1:\n",
    "            self.downsample = nn.MaxPool2d(stride, stride=stride)\n",
    "        if in_channels != out_channels:\n",
    "            self.project = nn.Conv2dBnAct(in_channels, out_channels, kernel_size=1, stride=1, pad_mode='same',\n",
    "                                          has_bias=False, has_bn=True, momentum=BN_MOMENTUM,\n",
    "                                          activation=None, after_fake=False)\n",
    "\n",
    "    def construct(self, x, residual=None, children=None):\n",
    "        \"\"\"construct each stage tree recurrently\"\"\"\n",
    "        children = () if children is None else children\n",
    "        bottom = self.downsample(x) if self.downsample else x\n",
    "        residual = self.project(bottom) if self.project else bottom\n",
    "        if self.level_root:\n",
    "            children += (bottom,)\n",
    "        x1 = self.tree1(x, residual)\n",
    "        if self.levels == 1:\n",
    "            x2 = self.tree2(x1)\n",
    "            ida_node = (x2, x1) + children\n",
    "            x = self.root(ida_node)\n",
    "        else:\n",
    "            children += (x1,)\n",
    "            x = self.tree2(x1, children=children)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DLA34(nn.Cell):\n",
    "    \"\"\"\n",
    "    Construct the downsampling deep aggregation network.\n",
    "\n",
    "    Args:\n",
    "        levels(list int): Tree height of each stage.\n",
    "        channels(list int): Input channel of each stage\n",
    "        block(Cell): Initial basic block. Default: BasicBlock.\n",
    "        residual_root(bool): Add residual or not. Default: False\n",
    "\n",
    "    Returns:\n",
    "        tuple of Tensor, the root node of each stage.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, levels, channels, block=None, residual_root=False):\n",
    "        super(DLA34, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.base_layer = nn.Conv2dBnAct(3, channels[0], kernel_size=7, stride=1, pad_mode='same',\n",
    "                                         has_bias=False, has_bn=True, momentum=BN_MOMENTUM,\n",
    "                                         activation='relu', after_fake=False)\n",
    "        self.level0 = self._make_conv_level(channels[0], channels[0], levels[0])\n",
    "        self.level1 = self._make_conv_level(channels[0], channels[1], levels[1], stride=2)\n",
    "        self.level2 = Tree(levels[2], block, channels[1], channels[2], 2,\n",
    "                           level_root=False, root_residual=residual_root)\n",
    "        self.level3 = Tree(levels[3], block, channels[2], channels[3], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "        self.level4 = Tree(levels[4], block, channels[3], channels[4], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "        self.level5 = Tree(levels[5], block, channels[4], channels[5], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "        self.dla_fn = [self.level0, self.level1, self.level2, self.level3, self.level4, self.level5]\n",
    "\n",
    "    def _make_conv_level(self, cin, cout, convs, stride=1, dilation=1):\n",
    "        modules = []\n",
    "        for i in range(convs):\n",
    "            modules.append(nn.Conv2dBnAct(cin, cout, kernel_size=3, stride=stride if i == 0 else 1,\n",
    "                                          pad_mode='pad', padding=dilation, has_bias=False, dilation=dilation,\n",
    "                                          has_bn=True, momentum=BN_MOMENTUM, activation='relu', after_fake=False))\n",
    "            cin = cout\n",
    "        return nn.SequentialCell(modules)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"\n",
    "        Construct the downsampling deep aggregation network.\n",
    "        \"\"\"\n",
    "        y = []\n",
    "        x = self.base_layer(x)\n",
    "        for i in range(len(self.channels)):\n",
    "            x = self.dla_fn[i](x)\n",
    "            y.append(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "class DeformConv(nn.Cell):\n",
    "    \"\"\"\n",
    "    Deformable convolution v2.\n",
    "\n",
    "    Args:\n",
    "        cin(int): Input channel\n",
    "        cout(int): Output_channel\n",
    "\n",
    "    Returns:\n",
    "        Tensor, results after deformable convolution and activation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cin, cout):\n",
    "        super(DeformConv, self).__init__()\n",
    "        self.actf = nn.SequentialCell([\n",
    "            nn.BatchNorm2d(cout, momentum=BN_MOMENTUM),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "        self.conv = nn.Conv2d(cin, cout, kernel_size=3, stride=1, has_bias=False)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"\n",
    "        Deformable convolution v2.\n",
    "        \"\"\"\n",
    "        x = self.conv(x)\n",
    "        x = self.actf(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class IDAUp(nn.Cell):\n",
    "    \"\"\"IDAUp sample.\"\"\"\n",
    "\n",
    "    def __init__(self, o, channels, up_f):\n",
    "        super(IDAUp, self).__init__()\n",
    "        proj_list = []\n",
    "        up_list = []\n",
    "        node_list = []\n",
    "        for i in range(1, len(channels)):\n",
    "            c = channels[i]\n",
    "            f = int(up_f[i])\n",
    "            proj = DeformConv(c, o)\n",
    "            node = DeformConv(o, o)\n",
    "            up = nn.Conv2dTranspose(o, o, f * 2, stride=f, pad_mode='pad', padding=f // 2, group=o)\n",
    "            proj_list.append(proj)\n",
    "            up_list.append(up)\n",
    "            node_list.append(node)\n",
    "        self.proj = nn.CellList(proj_list)\n",
    "        self.up = nn.CellList(up_list)\n",
    "        self.node = nn.CellList(node_list)\n",
    "\n",
    "    def construct(self, layers, startp, endp):\n",
    "        \"\"\"IDAUp sample.\"\"\"\n",
    "        for i in range(startp + 1, endp):\n",
    "            upsample = self.up[i - startp - 1]\n",
    "            project = self.proj[i - startp - 1]\n",
    "            layers[i] = upsample(project(layers[i].copy()))\n",
    "            node = self.node[i - startp - 1]\n",
    "            layers[i] = node(layers[i] + layers[i - 1])\n",
    "        return layers\n",
    "\n",
    "\n",
    "class DLAUp(nn.Cell):\n",
    "    \"\"\"DLAUp sample.\"\"\"\n",
    "\n",
    "    def __init__(self, startp, channels, scales, in_channels=None):\n",
    "        super(DLAUp, self).__init__()\n",
    "        self.startp = startp\n",
    "        if in_channels is None:\n",
    "            in_channels = channels\n",
    "        self.channels = channels\n",
    "        channels = list(channels)\n",
    "        scales = np.array(scales, dtype=int)\n",
    "        self.ida = []\n",
    "        for i in range(len(channels) - 1):\n",
    "            j = -i - 2\n",
    "            self.ida.append(IDAUp(channels[j], in_channels[j:],\n",
    "                                  scales[j:] // scales[j]))\n",
    "            # setattr(self, 'ida_{}'.format(i),\n",
    "            #         IDAUp(channels[j], in_channels[j:],\n",
    "            #               scales[j:] // scales[j]))\n",
    "            scales[j + 1:] = scales[j]\n",
    "            in_channels[j + 1:] = [channels[j] for _ in channels[j + 1:]]\n",
    "        self.ida_nfs = nn.CellList(self.ida)\n",
    "\n",
    "    def construct(self, layers):\n",
    "        \"\"\"DLAUp sample.\"\"\"\n",
    "        out = [layers[-1]]  # start with 32\n",
    "        for i in range(len(layers) - self.startp - 1):\n",
    "            ida = self.ida_nfs[i]\n",
    "            layers = ida(layers, len(layers) - i - 2, len(layers))\n",
    "            out.append(layers[-1])\n",
    "        a = []\n",
    "        i = len(out)\n",
    "        while i > 0:\n",
    "            a.append(out[i - 1])\n",
    "            i -= 1\n",
    "        return a\n",
    "\n",
    "\n",
    "class DLASegConv(nn.Cell):\n",
    "    \"\"\"\n",
    "    The DLA backbone network.\n",
    "\n",
    "    Args:\n",
    "        down_ratio(int): The ratio of input and output resolution\n",
    "        last_level(int): The ending stage of the final upsampling\n",
    "        stage_levels(list int): The tree height of each stage block\n",
    "        stage_channels(list int): The feature channel of each stage\n",
    "\n",
    "    Returns:\n",
    "        Tensor, the feature map extracted by dla network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, heads, down_ratio, final_kernel,\n",
    "                 last_level, head_conv, out_channel=0, is_training=True):\n",
    "        super(DLASegConv, self).__init__()\n",
    "        assert down_ratio in [2, 4, 8, 16]\n",
    "        self.first_level = int(np.log2(down_ratio))\n",
    "        self.last_level = last_level\n",
    "        self.is_training = is_training\n",
    "        self.base = DLA34([1, 1, 1, 2, 2, 1], [16, 32, 64, 128, 256, 512], block=BasicBlock)\n",
    "        channels = [16, 32, 64, 128, 256, 512]\n",
    "        scales = [2 ** i for i in range(len(channels[self.first_level:]))]\n",
    "        # self.dla_up = DLAUp(self.first_level, stage_channels[self.first_level:], last_level)\n",
    "        self.dla_up = DLAUp(self.first_level, channels[self.first_level:], scales)\n",
    "        if out_channel == 0:\n",
    "            out_channel = channels[self.first_level]\n",
    "        self.ida_up = IDAUp(out_channel, channels[self.first_level:self.last_level],\n",
    "                            [2 ** i for i in range(self.last_level - self.first_level)])\n",
    "        self.heads = heads\n",
    "        for head in self.heads:\n",
    "            classes = self.heads[head]\n",
    "            if head_conv > 0:\n",
    "                if 'hm' in head:\n",
    "                    conv2d = nn.Conv2d(head_conv, classes, kernel_size=final_kernel, has_bias=True,\n",
    "                                       bias_init=Constant(-2.19))\n",
    "                    self.hm_fc = nn.SequentialCell(\n",
    "                        [nn.Conv2d(channels[self.first_level], head_conv, kernel_size=3, has_bias=True), nn.ReLU(),\n",
    "                         conv2d])\n",
    "                elif 'wh' in head:\n",
    "                    conv2d = nn.Conv2d(head_conv, classes, kernel_size=final_kernel, has_bias=True)\n",
    "                    self.wh_fc = nn.SequentialCell(\n",
    "                        [nn.Conv2d(channels[self.first_level], head_conv, kernel_size=3, has_bias=True), nn.ReLU(),\n",
    "                         conv2d])\n",
    "                elif 'id' in head:\n",
    "                    conv2d = nn.Conv2d(head_conv, classes, kernel_size=final_kernel, has_bias=True)\n",
    "                    self.id_fc = nn.SequentialCell(\n",
    "                        [nn.Conv2d(channels[self.first_level], head_conv, kernel_size=3, has_bias=True), nn.ReLU(),\n",
    "                         conv2d])\n",
    "                else:\n",
    "                    conv2d = nn.Conv2d(head_conv, classes, kernel_size=final_kernel, has_bias=True)\n",
    "                    self.reg_fc = nn.SequentialCell(\n",
    "                        [nn.Conv2d(channels[self.first_level], head_conv, kernel_size=3, has_bias=True), nn.ReLU(),\n",
    "                         conv2d])\n",
    "            else:\n",
    "                if 'hm' in head:\n",
    "                    self.hm_fc = nn.Conv2d(channels[self.first_level], classes, kernel_size=final_kernel, has_bias=True,\n",
    "                                           bias_init=Constant(-2.19))\n",
    "                elif 'wh' in head:\n",
    "                    self.wh_fc = nn.Conv2d(channels[self.first_level], classes, kernel_size=final_kernel, has_bias=True)\n",
    "                elif 'id' in head:\n",
    "                    self.id_fc = nn.Conv2d(channels[self.first_level], classes, kernel_size=final_kernel, has_bias=True)\n",
    "                else:\n",
    "                    self.reg_fc = nn.Conv2d(channels[self.first_level], classes, kernel_size=final_kernel,\n",
    "                                            has_bias=True)\n",
    "\n",
    "    def construct(self, image):\n",
    "        \"\"\"The DLA backbone network.\"\"\"\n",
    "        x = self.base(image)\n",
    "        x = self.dla_up(x)\n",
    "        y = []\n",
    "        for i in range(self.last_level - self.first_level):\n",
    "            y.append(x[i].copy())\n",
    "        y = self.ida_up(y, 0, len(y))\n",
    "        hm = self.hm_fc(y[-1])\n",
    "        wh = self.wh_fc(y[-1])\n",
    "        feature_id = self.id_fc(y[-1])\n",
    "        reg = self.reg_fc(y[-1])\n",
    "        feature = {\"hm\": hm, \"feature_id\": feature_id, \"wh\": wh, \"reg\": reg}\n",
    "        return feature\n",
    "\n",
    "\n",
    "\n",
    "net = DLASegConv(opt.heads,\n",
    "                     down_ratio=4,\n",
    "                     final_kernel=1,\n",
    "                     last_level=5,\n",
    "                     head_conv=256)\n",
    "net = net.set_train()\n",
    "# param_dict = load_checkpoint(load_path)\n",
    "# load_param_into_net(net, param_dict)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Loss and logger"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(24966:139931493070656,MainProcess):2022-10-31-12:52:33.696.498 [mindspore/train/model.py:1075] For LossCallback callback, {'begin', 'end', 'step_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training : device_number=1,per_step_size=2801,batch_size=2, epoch=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] KERNEL(24966,7f4456eff740,python3.8):2022-10-31-12:52:57.777.156 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel.cc:40] CheckDeviceSm] It is recommended to use devices with a computing capacity >= 7, but the current device's computing capacity is 6\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.common.parameter import Parameter\n",
    "import cv2\n",
    "# Copyright 2021 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Functional Cells to be used.\n",
    "\"\"\"\n",
    "\n",
    "import mindspore.nn as nn\n",
    "\n",
    "\n",
    "class GatherFeature(nn.Cell):\n",
    "    \"\"\"\n",
    "    Gather feature at specified position\n",
    "\n",
    "    Args: None\n",
    "\n",
    "    Returns:\n",
    "        Tensor, feature at spectified position\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GatherFeature, self).__init__()\n",
    "        self.tile = ops.Tile()\n",
    "        self.shape = ops.Shape()\n",
    "        self.concat = ops.Concat(axis=1)\n",
    "        self.reshape = ops.Reshape()\n",
    "        self.gather_nd = ops.GatherNd()\n",
    "\n",
    "    def construct(self, feat, ind):\n",
    "        \"\"\"gather by specified index\"\"\"\n",
    "        # (b, N)->(b*N, 1)\n",
    "        b, N = self.shape(ind)\n",
    "        ind = self.reshape(ind, (-1, 1))\n",
    "        ind_b = nn.Range(0, b, 1)()\n",
    "        ind_b = self.reshape(ind_b, (-1, 1))\n",
    "        ind_b = self.tile(ind_b, (1, N))\n",
    "        ind_b = self.reshape(ind_b, (-1, 1))\n",
    "        index = self.concat((ind_b, ind))\n",
    "        # (b, N, 2)\n",
    "        index = self.reshape(index, (b, N, -1))\n",
    "        # (b, N, c)\n",
    "        feat = self.gather_nd(feat, index)\n",
    "        return feat\n",
    "\n",
    "\n",
    "class TransposeGatherFeature(nn.Cell):\n",
    "    \"\"\"\n",
    "    Transpose and gather feature at specified position\n",
    "\n",
    "    Args: None\n",
    "\n",
    "    Returns:\n",
    "        Tensor, feature at spectified position\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TransposeGatherFeature, self).__init__()\n",
    "        self.shape = ops.Shape()\n",
    "        self.reshape = ops.Reshape()\n",
    "        self.transpose = ops.Transpose()\n",
    "        self.perm_list = (0, 2, 3, 1)\n",
    "        self.gather_feat = GatherFeature()\n",
    "\n",
    "    def construct(self, feat, ind):\n",
    "        \"\"\"(b, c, h, w)->(b, h*w, c)\"\"\"\n",
    "        feat = self.transpose(feat, self.perm_list)\n",
    "        b, _, _, c = self.shape(feat)\n",
    "        feat = self.reshape(feat, (b, -1, c))\n",
    "        # (b, N, c)\n",
    "        feat = self.gather_feat(feat, ind)\n",
    "        return feat\n",
    "\n",
    "\n",
    "class Sigmoid(nn.Cell):\n",
    "    \"\"\"\n",
    "    Sigmoid and then Clip by value\n",
    "\n",
    "    Args: None\n",
    "\n",
    "    Returns:\n",
    "        Tensor, feature after sigmoid and clip.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Sigmoid, self).__init__()\n",
    "        self.cast = ops.Cast()\n",
    "        self.dtype = ops.DType()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.clip_by_value = ops.clip_by_value\n",
    "\n",
    "    def construct(self, x, min_value=1e-4, max_value=1 - 1e-4):\n",
    "        \"\"\"Sigmoid and then Clip by value\"\"\"\n",
    "        x = self.sigmoid(x)\n",
    "        dt = self.dtype(x)\n",
    "        x = self.clip_by_value(x, self.cast(ops.tuple_to_array((min_value,)), dt),\n",
    "                               self.cast(ops.tuple_to_array((max_value,)), dt))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Cell):\n",
    "    \"\"\"\n",
    "    Warpper for focal loss.\n",
    "\n",
    "    Args:\n",
    "        alpha(int): Super parameter in focal loss to mimic loss weight. Default: 2.\n",
    "        beta(int): Super parameter in focal loss to mimic imbalance between positive and negative samples. Default: 4.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, focal loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=2, beta=4):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.pow = ops.Pow()\n",
    "        self.log = ops.Log()\n",
    "        self.select = ops.Select()\n",
    "        self.equal = ops.Equal()\n",
    "        self.less = ops.Less()\n",
    "        self.cast = ops.Cast()\n",
    "        self.fill = ops.Fill()\n",
    "        self.dtype = ops.DType()\n",
    "        self.shape = ops.Shape()\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "\n",
    "    def construct(self, out, target):\n",
    "        \"\"\"focal loss\"\"\"\n",
    "        pos_inds = self.cast(self.equal(target, 1.0), ms.float32)\n",
    "        neg_inds = self.cast(self.less(target, 1.0), ms.float32)\n",
    "        neg_weights = self.pow(1 - target, self.beta)\n",
    "\n",
    "        pos_loss = self.log(out) * self.pow(1 - out, self.alpha) * pos_inds\n",
    "        neg_loss = self.log(1 - out) * self.pow(out, self.alpha) * neg_weights * neg_inds\n",
    "\n",
    "        num_pos = self.reduce_sum(pos_inds, ())\n",
    "        num_pos = self.select(self.equal(num_pos, 0.0),\n",
    "                              self.fill(self.dtype(num_pos), self.shape(num_pos), 1.0), num_pos)\n",
    "        pos_loss = self.reduce_sum(pos_loss, ())\n",
    "        neg_loss = self.reduce_sum(neg_loss, ())\n",
    "        loss = - (pos_loss + neg_loss) / num_pos\n",
    "        return loss\n",
    "\n",
    "\n",
    "class RegLoss(nn.Cell):\n",
    "    \"\"\"\n",
    "    Warpper for regression loss.\n",
    "\n",
    "    Args:\n",
    "        mode(str): L1 or Smoothed L1 loss. Default: \"l1\"\n",
    "\n",
    "    Returns:\n",
    "        Tensor, regression loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode='l1'):\n",
    "        super(RegLoss, self).__init__()\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.cast = ops.Cast()\n",
    "        self.expand_dims = ops.ExpandDims()\n",
    "        self.reshape = ops.Reshape()\n",
    "        self.gather_feature = TransposeGatherFeature()\n",
    "        if mode == 'l1':\n",
    "            self.loss = nn.L1Loss(reduction='sum')\n",
    "        elif mode == 'sl1':\n",
    "            self.loss = nn.SmoothL1Loss()\n",
    "        else:\n",
    "            self.loss = None\n",
    "\n",
    "    def construct(self, output, mask, ind, target):\n",
    "        \"\"\"Warpper for regression loss.\"\"\"\n",
    "        pred = self.gather_feature(output, ind)\n",
    "        mask = self.cast(mask, ms.float32)\n",
    "        num = self.reduce_sum(mask, ())\n",
    "        mask = self.expand_dims(mask, 2)\n",
    "        target = target * mask\n",
    "        pred = pred * mask\n",
    "        regr_loss = self.loss(pred, target)\n",
    "        regr_loss = regr_loss / (num + 1e-4)\n",
    "        return regr_loss\n",
    "\n",
    "\n",
    "class CenterNetMultiPoseLossCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    Provide pose estimation network losses.\n",
    "\n",
    "    Args:\n",
    "        net_config: The config info of CenterNet network.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, total loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        super(CenterNetMultiPoseLossCell, self).__init__()\n",
    "        self.crit = FocalLoss()\n",
    "        # self.crit_wh = RegWeightedL1Loss() if not config.net.dense_hp else nn.L1Loss(reduction='sum')\n",
    "        self.crit_wh = RegLoss(opt.reg_loss)\n",
    "        # wh\n",
    "        self.crit_reg = RegLoss(opt.reg_loss)  # reg_loss = 'l1'\n",
    "        self.hm_weight = opt.hm_weight  # hm_weight = 1 :loss weight for keypoint heatmaps\n",
    "        self.wh_weight = opt.wh_weight  # wh_weight = 0.1 : loss weight for bounding box size\n",
    "        self.off_weight = opt.off_weight  # off_weight = 1 : loss weight for keypoint local offsets\n",
    "        self.reg_offset = opt.reg_offset  # reg_offset = True : regress local offset\n",
    "\n",
    "        self.scalar_summary = ops.ScalarSummary()  # store losses scalars\n",
    "\n",
    "        self.reg_ind = \"reg\" if self.reg_offset else \"wh\"\n",
    "\n",
    "        # define id\n",
    "        self.emb_dim = opt.reid_dim  # dataset.reid_dim = 128\n",
    "        self.nID = opt.nID  # nId = 14455\n",
    "        self.classifier = nn.Dense(self.emb_dim, self.nID).to_float(ms.float16)\n",
    "        self.IDLoss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "        self.emb_scale = math.sqrt(2) * math.log(self.nID - 1)  # fix np\n",
    "        self.s_det = Parameter(Tensor(-1.85 * np.ones(1), ms.float32))\n",
    "        self.s_id = Parameter(Tensor(-1.05 * np.ones(1), ms.float32))\n",
    "\n",
    "        self.normalize = ops.L2Normalize(axis=1)\n",
    "        self.greater = ops.Greater()\n",
    "        self.expand_dims = ops.ExpandDims()\n",
    "        self.tile = ops.Tile()\n",
    "        self.multiples_1 = (1, 1, 128)\n",
    "        self.select = ops.Select()\n",
    "        self.zeros = ops.Zeros()\n",
    "        self.exp = ops.Exp()\n",
    "        self.squeeze = ops.Squeeze(0)\n",
    "        self.TransposeGatherFeature = TransposeGatherFeature()\n",
    "        self.reshape = ops.Reshape()\n",
    "        self.reshape_mul = opt.batch_size * opt.K\n",
    "        self.cast = ops.Cast()\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def construct(self, feature, hm, reg_mask, ind, wh, reg, ids):\n",
    "        \"\"\"Defines the computation performed.\"\"\"\n",
    "        output_hm = feature[\"hm\"]  # FocalLoss()\n",
    "        output_hm = self.sigmoid(output_hm)\n",
    "\n",
    "        hm_loss = self.crit(output_hm, hm)\n",
    "        self.scalar_summary(\"hm_loss\", hm_loss)\n",
    "\n",
    "        output_id = feature[\"feature_id\"]  # SoftmaxCrossEntropyWithLogits()\n",
    "        id_head = self.TransposeGatherFeature(output_id, ind)  # id_head=[1,500,128]\n",
    "\n",
    "        # id_head = id_head[reg_mask > 0]\n",
    "        cond = self.greater(reg_mask, 0)  # cond=[1,500]\n",
    "        cond_cast = self.cast(cond, ms.int32)\n",
    "        expand_output = self.expand_dims(cond_cast, 2)\n",
    "        tile_out = self.tile(expand_output, self.multiples_1)\n",
    "        tile_cast = self.cast(tile_out, ms.bool_)\n",
    "        fill_zero = self.zeros(id_head.shape, ms.float32)  # fill_zero=[1,500,128]\n",
    "        id_head = self.select(tile_cast, id_head, fill_zero)  # id_head=[1,500,128]\n",
    "\n",
    "        id_head = self.emb_scale * self.normalize(id_head)  # id_head=[1,500,128]\n",
    "        # id_head = self.emb_scale * ops.L2Normalize(id_head)\n",
    "\n",
    "        zero_input = self.zeros(ids.shape, ms.int32)\n",
    "        id_target = self.select(self.greater(ids, 0), ids, zero_input)  # id_target=[1,500]\n",
    "\n",
    "        c_out = self.cast(id_head, ms.float16)\n",
    "        id_output = self.classifier(c_out)  # id_output=[1,500,14455]\n",
    "        id_output = self.cast(id_output, ms.float32)\n",
    "\n",
    "        id_loss = self.IDLoss(id_output, id_target)\n",
    "        self.scalar_summary(\"id_loss\", id_loss)\n",
    "\n",
    "        output_wh = feature[\"wh\"]  # Regl1Loss\n",
    "        wh_loss = self.crit_reg(output_wh, reg_mask, ind, wh)\n",
    "        self.scalar_summary(\"wh_loss\", wh_loss)\n",
    "\n",
    "        off_loss = 0\n",
    "        if self.reg_offset and self.off_weight > 0:  # Regl1Loss\n",
    "            output_reg = feature[self.reg_ind]\n",
    "            off_loss = self.crit_reg(output_reg, reg_mask, ind, reg)\n",
    "        self.scalar_summary(\"off_loss\", off_loss)\n",
    "\n",
    "        det_loss = self.hm_weight * hm_loss + self.wh_weight * wh_loss + self.off_weight * off_loss\n",
    "        self.scalar_summary(\"det_loss\", det_loss)\n",
    "        loss = self.exp(-self.s_det) * det_loss + self.exp(-self.s_id) * id_loss + (self.s_det + self.s_id)\n",
    "        loss *= 0.5\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "from mindspore import dtype as mstype\n",
    "\n",
    "def dynamic_lr(num_epoch_per_decay, total_epochs, steps_per_epoch):\n",
    "    \"\"\"dynamic learning rate generator\"\"\"\n",
    "    lr_each_step = []\n",
    "    total_steps = steps_per_epoch * total_epochs\n",
    "    decay_steps = steps_per_epoch * num_epoch_per_decay\n",
    "    lr = nn.PolynomialDecayLR(1e-4, 1e-5, decay_steps, 0.5)\n",
    "    for i in range(total_steps):\n",
    "        if i < decay_steps:\n",
    "            i = Tensor(i, mstype.int32)\n",
    "            lr_each_step.append(lr(i).asnumpy())\n",
    "        else:\n",
    "            lr_each_step.append(1e-5)\n",
    "    return lr_each_step\n",
    "\n",
    "\n",
    "\n",
    "class WithLossCell(nn.Cell):\n",
    "    \"\"\"Cell with loss function..\"\"\"\n",
    "\n",
    "    def __init__(self, net, loss):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._net = net\n",
    "        self._loss = loss\n",
    "\n",
    "    def construct(self, image, hm, reg_mask, ind, wh, reg, ids):\n",
    "        \"\"\"Cell with loss function.\"\"\"\n",
    "        feature = self._net(image)\n",
    "        return self._loss(feature, hm, reg_mask, ind, wh, reg, ids)\n",
    "\n",
    "    @property\n",
    "    def backbone_network(self):\n",
    "        \"\"\"Return net.\"\"\"\n",
    "        return self._net\n",
    "\n",
    "\n",
    "class WithNetCell(nn.Cell):\n",
    "    \"\"\"Cell with infer_net function..\"\"\"\n",
    "\n",
    "    def __init__(self, net, infer_net):\n",
    "        super(WithNetCell, self).__init__(auto_prefix=False)\n",
    "        self._net = net\n",
    "        self._infer_net = infer_net\n",
    "\n",
    "    def construct(self, image):\n",
    "        \"\"\"Cell with loss function.\"\"\"\n",
    "        feature = self._net(image)\n",
    "        return self._infer_net(feature)\n",
    "\n",
    "\n",
    "from mindspore.train.callback import Callback\n",
    "\n",
    "class LossCallback(Callback):\n",
    "    \"\"\"StopAtTime\"\"\"\n",
    "\n",
    "    def __init__(self, bach_size):\n",
    "        \"\"\"init\"\"\"\n",
    "        super(LossCallback, self).__init__()\n",
    "        self.bach_size = bach_size\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def begin(self, run_context):\n",
    "        \"\"\"train begin\"\"\"\n",
    "        cb_params = run_context.original_args()\n",
    "        batch_num = cb_params.batch_num\n",
    "        epoch_num = cb_params.epoch_num\n",
    "        device_number = cb_params.device_number\n",
    "\n",
    "        print(\"Starting Training : device_number={},per_step_size={},batch_size={}, epoch={}\".format(device_number,\n",
    "                                                                                                     batch_num,\n",
    "                                                                                                     self.bach_size,\n",
    "                                                                                                     epoch_num))\n",
    "\n",
    "    def step_end(self, run_context):\n",
    "        \"\"\"step end\"\"\"\n",
    "        cb_params = run_context.original_args()\n",
    "        cur_epoch_num = cb_params.cur_epoch_num\n",
    "        cur_step_num = cb_params.cur_step_num\n",
    "        loss = cb_params.net_outputs[0].asnumpy()\n",
    "        batch_num = cb_params.batch_num\n",
    "        if cur_step_num > batch_num:\n",
    "            cur_step_num = cur_step_num % batch_num + 1\n",
    "        epoch_num = cb_params.epoch_num\n",
    "        print(\"epoch: {}/{}, step: {}/{}, loss is {}\".format(cur_epoch_num, epoch_num, cur_step_num, batch_num, loss))\n",
    "\n",
    "    def end(self, run_context):\n",
    "        \"\"\"train end\"\"\"\n",
    "        cb_params = run_context.original_args()\n",
    "        device_number = cb_params.device_number\n",
    "        time_end = time.time()\n",
    "        seconds = time_end - self.time_start\n",
    "        seconds = seconds % (24 * 3600)\n",
    "        hour = seconds // 3600\n",
    "        seconds %= 3600\n",
    "        minutes = seconds // 60\n",
    "        seconds %= 60\n",
    "        print(device_number, \"device totally cost:%02d:%02d:%02d\" % (hour, minutes, seconds))\n",
    "\n",
    "\n",
    "from mindspore.train.callback import TimeMonitor, ModelCheckpoint, CheckpointConfig\n",
    "from mindspore.train.callback import SummaryCollector\n",
    "from mindspore import Model\n",
    "\n",
    "loss = CenterNetMultiPoseLossCell(opt)\n",
    "lr = Tensor(dynamic_lr(20, opt.num_epochs, batch_dataset_size), mstype.float32)\n",
    "optimizer = nn.Adam(net.trainable_params(), learning_rate=lr)\n",
    "net_with_loss = WithLossCell(net, loss)\n",
    "fairmot_net = nn.TrainOneStepCell(net_with_loss, optimizer)\n",
    "\n",
    "    # define callback\n",
    "\n",
    "summary_dir = './summary'\n",
    "summary_cb = SummaryCollector(summary_dir, collect_freq=1)\n",
    "loss_cb = LossCallback(opt.batch_size)\n",
    "time_cb = TimeMonitor()\n",
    "config_ckpt = CheckpointConfig(saved_network=net)\n",
    "\n",
    "ckpoint_cb = ModelCheckpoint(prefix='Fairmot', directory='./ckpt/', config=config_ckpt)\n",
    "callbacks = [loss_cb, ckpoint_cb, time_cb, summary_cb]\n",
    "\n",
    "model = Model(fairmot_net)\n",
    "# model.train(opt.num_epochs, Ms_dataset, callbacks=callbacks, dataset_sink_mode=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Fix size testing.\n",
      "heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 13:10:12 [INFO]: start seq: MOT20-01\n",
      "2022-10-31 13:10:12 [INFO]: Processing frame 0 (100000.00 fps)\n",
      "[WARNING] KERNEL(31056,7fbb6bd4f740,python3.8):2022-10-31-13:10:19.371.491 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel_factory.cc:147] CheckSM] It is recommended to use devices with a computing capacity >= 7, but the current device's computing capacity is 6\n",
      "2022-10-31 13:10:23 [INFO]: Processing frame 20 (2.13 fps)\n",
      "2022-10-31 13:10:28 [INFO]: Processing frame 40 (3.50 fps)\n",
      "2022-10-31 13:10:32 [INFO]: Processing frame 60 (4.47 fps)\n",
      "2022-10-31 13:10:36 [INFO]: Processing frame 80 (5.21 fps)\n",
      "2022-10-31 13:10:40 [INFO]: Processing frame 100 (5.79 fps)\n",
      "2022-10-31 13:10:43 [INFO]: Processing frame 120 (6.27 fps)\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "import os\n",
    "import logging\n",
    "import os.path as osp\n",
    "from mindspore import Tensor, context\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.train.serialization import load_checkpoint\n",
    "import cv2\n",
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "from src.backbone_dla_conv import DLASegConv\n",
    "from src.infer_net import InferNet\n",
    "from src.config import Opts\n",
    "from src.fairmot_pose import WithNetCell\n",
    "from src.tracking_utils import visualization as vis\n",
    "from src.tracker.multitracker import JDETracker\n",
    "from src.tracking_utils.log import logger\n",
    "from src.tracking_utils.utils import mkdir_if_missing\n",
    "from src.tracking_utils.evaluation import Evaluator\n",
    "from src.tracking_utils.timer import Timer\n",
    "import src.utils.jde as datasets\n",
    "\n",
    "\n",
    "def write_results(filename, results, data_type):\n",
    "    \"\"\"write eval results.\"\"\"\n",
    "    if data_type == 'mot':\n",
    "        save_format = '{frame},{id},{x1},{y1},{w},{h},1,-1,-1,-1\\n'\n",
    "    elif data_type == 'kitti':\n",
    "        save_format = '{frame} {id} pedestrian 0 0 -10 {x1} {y1} {x2} {y2} -10 -10 -10 -1000 -1000 -1000 -10\\n'\n",
    "    else:\n",
    "        raise ValueError(data_type)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        for frame_id, tlwhs, track_ids in results:\n",
    "            if data_type == 'kitti':\n",
    "                frame_id -= 1\n",
    "            for tlwh, track_id in zip(tlwhs, track_ids):\n",
    "                if track_id < 0:\n",
    "                    continue\n",
    "                x1, y1, w, h = tlwh\n",
    "                x2, y2 = x1 + w, y1 + h\n",
    "                line = save_format.format(frame=frame_id, id=track_id, x1=x1, y1=y1, x2=x2, y2=y2, w=w, h=h)\n",
    "                f.write(line)\n",
    "    logger.info('save results to %s', filename)\n",
    "\n",
    "\n",
    "def eval_seq(opt, net, dataloader, data_type, result_filename, save_dir=None, show_image=True, frame_rate=30):\n",
    "    \"\"\"evaluation sequence.\"\"\"\n",
    "    if save_dir:\n",
    "        mkdir_if_missing(save_dir)\n",
    "    tracker = JDETracker(opt, frame_rate=frame_rate)\n",
    "    timer = Timer()\n",
    "    results = []\n",
    "    frame_id = 0\n",
    "    # for path, img, img0 in dataloader:\n",
    "    for _, img, img0 in dataloader:\n",
    "        if frame_id % 20 == 0:\n",
    "            logger.info('Processing frame {} ({:.2f} fps)'.format(frame_id, 1. / max(1e-5, timer.average_time)))\n",
    "        # run tracking\n",
    "        timer.tic()\n",
    "        blob = np.expand_dims(img, 0)\n",
    "        blob = Tensor(blob, mstype.float32)\n",
    "        img0 = Tensor(img0, mstype.float32)\n",
    "        height, width = img0.shape[0], img0.shape[1]\n",
    "        inp_height, inp_width = [blob.shape[2], blob.shape[3]]\n",
    "        c = np.array([width / 2., height / 2.], dtype=np.float32)\n",
    "        s = max(float(inp_width) / float(inp_height) * height, width) * 1.0\n",
    "        meta = {'c': c, 's': s, 'out_height': inp_height // opt.down_ratio,\n",
    "                'out_width': inp_width // opt.down_ratio}\n",
    "        id_feature, dets = net(blob)\n",
    "        online_targets = tracker.update(id_feature.asnumpy(), dets, meta)\n",
    "        online_tlwhs = []\n",
    "        online_ids = []\n",
    "        for t in online_targets:\n",
    "            tlwh = t.tlwh\n",
    "            tid = t.track_id\n",
    "            vertical = tlwh[2] / tlwh[3] > 1.6\n",
    "            if tlwh[2] * tlwh[3] > opt.min_box_area and not vertical:\n",
    "                online_tlwhs.append(tlwh)\n",
    "                online_ids.append(tid)\n",
    "        timer.toc()\n",
    "        results.append((frame_id + 1, online_tlwhs, online_ids))\n",
    "        if show_image or save_dir is not None:\n",
    "            online_im = vis.plot_tracking(img0, online_tlwhs, online_ids, frame_id=frame_id,\n",
    "                                          fps=1. / timer.average_time)\n",
    "        if show_image:\n",
    "            cv2.imshow('online_im', online_im)\n",
    "        if save_dir is not None:\n",
    "            cv2.imwrite(os.path.join(save_dir, '{:05d}.jpg'.format(frame_id)), online_im)\n",
    "        frame_id += 1\n",
    "    write_results(result_filename, results, data_type)\n",
    "    return frame_id, timer.average_time, timer.calls\n",
    "\n",
    "\n",
    "def main(opt, data_root, seqs=None, exp_name='MOT17_test_public_dla34',\n",
    "         save_images=True, save_videos=False, show_image=False):\n",
    "    \"\"\"evaluation sequence.\"\"\"\n",
    "    logger.setLevel(logging.INFO)\n",
    "    result_root = os.path.join(data_root, '..', 'results', exp_name)\n",
    "    mkdir_if_missing(result_root)\n",
    "    data_type = 'mot'\n",
    "    # run tracking\n",
    "    accs = []\n",
    "    n_frame = 0\n",
    "    timer_avgs, timer_calls = [], []\n",
    "    backbone_net = DLASegConv(opt.heads,\n",
    "                              down_ratio=4,\n",
    "                              final_kernel=1,\n",
    "                              last_level=5,\n",
    "                              head_conv=256)\n",
    "    load_checkpoint(opt.load_model, net=backbone_net)\n",
    "    infer_net = InferNet()\n",
    "    net = WithNetCell(backbone_net, infer_net)\n",
    "    net.set_train(False)\n",
    "    for sequence in seqs:\n",
    "        output_dir = os.path.join(data_root, '..', 'outputs', exp_name, sequence) \\\n",
    "            if save_images or save_videos else None\n",
    "        logger.info('start seq: %s', sequence)\n",
    "        dataloader = datasets.LoadImages(osp.join(data_root, sequence, 'img1'), (1088, 608))\n",
    "        result_filename = os.path.join(result_root, '{}.txt'.format(sequence))\n",
    "        meta_info = open(os.path.join(data_root, sequence, 'seqinfo.ini')).read()\n",
    "        frame_rate = int(meta_info[meta_info.find('frameRate') + 10:meta_info.find('\\nseqLength')])\n",
    "        nf, ta, tc = eval_seq(opt, net, dataloader, data_type, result_filename,\n",
    "                              save_dir=output_dir, show_image=show_image, frame_rate=frame_rate)\n",
    "        n_frame += nf\n",
    "        timer_avgs.append(ta)\n",
    "        timer_calls.append(tc)\n",
    "        logger.info('Evaluate seq: %s', sequence)\n",
    "        evaluator = Evaluator(data_root, sequence, data_type)\n",
    "        accs.append(evaluator.eval_file(result_filename))\n",
    "        if save_videos:\n",
    "            print(output_dir)\n",
    "            output_video_path = osp.join(output_dir, '{}.mp4'.format(sequence))\n",
    "            cmd_str = 'ffmpeg -f image2 -i {}/%05d.jpg -c:v copy {}'.format(output_dir, output_video_path)\n",
    "            os.system(cmd_str)\n",
    "    timer_avgs = np.asarray(timer_avgs)\n",
    "    timer_calls = np.asarray(timer_calls)\n",
    "    all_time = np.dot(timer_avgs, timer_calls)\n",
    "    avg_time = all_time / np.sum(timer_calls)\n",
    "    logger.info('Time elapsed: {:.2f} seconds, FPS: {:.2f}'.format(all_time, 1.0 / avg_time))\n",
    "\n",
    "    # get summary\n",
    "    metrics = mm.metrics.motchallenge_metrics\n",
    "    mh = mm.metrics.create()\n",
    "    summary = Evaluator.get_summary(accs, seqs, metrics)\n",
    "    strsummary = mm.io.render_summary(\n",
    "        summary,\n",
    "        formatters=mh.formatters,\n",
    "        namemap=mm.io.motchallenge_metric_names\n",
    "    )\n",
    "    print(strsummary)\n",
    "    Evaluator.save_summary(summary, os.path.join(result_root, 'summary_{}.xlsx'.format(exp_name)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    opts = Opts().get_config()\n",
    "    context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        device_target=opts.device,\n",
    "        device_id=opts.id,\n",
    "        save_graphs=False)\n",
    "    seqs_str = '''MOT20-01\n",
    "                  MOT20-02\n",
    "                  MOT20-03\n",
    "                  MOT20-05 '''\n",
    "    data_roots = os.path.join(opts.data_dir, 'MOT20/train')\n",
    "    seq = [seq.strip() for seq in seqs_str.split()]\n",
    "    main(opts,\n",
    "         data_root=data_roots,\n",
    "         seqs=seq,\n",
    "         exp_name='MOT20_distribute_dla34_conv',\n",
    "         show_image=False,\n",
    "         save_images=False,\n",
    "         save_videos=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}